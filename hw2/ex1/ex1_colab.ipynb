{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orLaNPzWc-nT",
        "outputId": "d8e5cc77-f9c0-48e5-b213-ef1844fbd68d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysNMOvrQc_Oe",
        "outputId": "3fabc5af-f76b-45a0-ebe5-957c266adf69"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Nov 16 23:53:09 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UgQQL1Zec_L_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile lab2_ex1.cu\n",
        "#include <stdio.h>\n",
        "#include <sys/time.h>\n",
        "\n",
        "#define TPB 128\n",
        "#define DataType double\n",
        "#define DOUBLE_MIN -5\n",
        "#define DOUBLE_MAX 5\n",
        "\n",
        "__global__ void vecAdd(DataType *in1, DataType *in2, DataType *out, int len) {\n",
        "  //@@ Insert code to implement vector addition here\n",
        "  int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  out[i] = in1[i] + in2[i];\n",
        "}\n",
        "\n",
        "//@@ Insert code to implement timer start\n",
        "void timerStart(struct timeval *start) {\n",
        "  gettimeofday(start, NULL);\n",
        "}\n",
        "\n",
        "//@@ Insert code to implement timer stop\n",
        "double timerStop(struct timeval *start) {\n",
        "  struct timeval end;\n",
        "  gettimeofday(&end, NULL);\n",
        "  double time = (end.tv_sec - start->tv_sec) * 1000.0;\n",
        "  time += (end.tv_usec - start->tv_usec) / 1000.0;\n",
        "  return time;\n",
        "}\n",
        "\n",
        "double randDouble(double min, double max) {\n",
        "  double scale = rand() / (double)RAND_MAX;\n",
        "  return min + scale * (max-min);\n",
        "}\n",
        "\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "\n",
        "  int inputLength;\n",
        "  DataType *hostInput1;\n",
        "  DataType *hostInput2;\n",
        "  DataType *hostOutput;\n",
        "  DataType *resultRef;\n",
        "  DataType *deviceInput1;\n",
        "  DataType *deviceInput2;\n",
        "  DataType *deviceOutput;\n",
        "\n",
        "  struct timeval copyToDevice, copyFromDevice, kernelExecution;\n",
        "  double copyToDeviceTime, copyFromDeviceTime, kernelExecutionTime;\n",
        "\n",
        "  //@@ Insert code below to read in inputLength from args\n",
        "  if(argc > 1){\n",
        "    inputLength = atoi(argv[1]);\n",
        "  }\n",
        "\n",
        "\n",
        "  printf(\"The input length is %d\\n\", inputLength);\n",
        "\n",
        "  //@@ Insert code below to allocate Host memory for input and output\n",
        "  hostInput1 = (DataType *)malloc(inputLength * sizeof(DataType));\n",
        "  hostInput2 = (DataType *)malloc(inputLength * sizeof(DataType));\n",
        "  hostOutput = (DataType *)malloc(inputLength * sizeof(DataType));\n",
        "  resultRef = (DataType *)malloc(inputLength * sizeof(DataType));\n",
        "\n",
        "\n",
        "  //@@ Insert code below to initialize hostInput1 and hostInput2 to random numbers, and create reference result in CPU\n",
        "  for(int i = 0; i < inputLength; ++i) {\n",
        "    hostInput1[i] = randDouble(DOUBLE_MIN, DOUBLE_MAX);\n",
        "    hostInput2[i] = randDouble(DOUBLE_MIN, DOUBLE_MAX);\n",
        "    //printf(\"host1: %d\", hostInput1[i]);\n",
        "    resultRef[i] = hostInput1[i] + hostInput2[i];\n",
        "  }\n",
        "\n",
        "\n",
        "  //@@ Insert code below to allocate GPU memory here\n",
        "  cudaMalloc((void **)&deviceInput1, inputLength * sizeof(DataType));\n",
        "  cudaMalloc((void **)&deviceInput2, inputLength * sizeof(DataType));\n",
        "  cudaMalloc((void **)&deviceOutput, inputLength * sizeof(DataType));\n",
        "\n",
        "\n",
        "  //@@ Insert code to below to Copy memory to the GPU here\n",
        "  timerStart(&copyToDevice);\n",
        "  cudaMemcpy(deviceInput1, hostInput1, inputLength * sizeof(DataType), cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(deviceInput2, hostInput2, inputLength * sizeof(DataType), cudaMemcpyHostToDevice);\n",
        "  copyToDeviceTime = timerStop(&copyToDevice);\n",
        "\n",
        "\n",
        "  //@@ Initialize the 1D grid and block dimensions here\n",
        "  dim3 DimGrid((inputLength+TPB-1)/TPB, 1, 1);\n",
        "  dim3 DimBlock(TPB, 1, 1);\n",
        "\n",
        "\n",
        "  //@@ Launch the GPU Kernel here\n",
        "  timerStart(&kernelExecution);\n",
        "  vecAdd<<<DimGrid, DimBlock>>>(deviceInput1, deviceInput2, deviceOutput, inputLength);\n",
        "  cudaDeviceSynchronize();\n",
        "  kernelExecutionTime = timerStop(&kernelExecution);\n",
        "\n",
        "\n",
        "  //@@ Copy the GPU memory back to the CPU here\n",
        "  timerStart(&copyFromDevice);\n",
        "  cudaMemcpy(hostOutput, deviceOutput, inputLength * sizeof(DataType), cudaMemcpyDeviceToHost);\n",
        "  copyFromDeviceTime = timerStop(&copyFromDevice);\n",
        "\n",
        "\n",
        "  //@@ Insert code below to compare the output with the reference\n",
        "  double diff = 0.0;\n",
        "  for(int i = 0; i < inputLength; ++i) {\n",
        "    diff += abs(hostOutput[i] - resultRef[i]);\n",
        "  }\n",
        "  printf(\"Average difference: %f\\n\\n\", diff/(double)inputLength);\n",
        "\n",
        "  printf(\"Copy to Device Time: %f ms\\n\", copyToDeviceTime);\n",
        "  printf(\"Kernel Execution Time: %f ms\\n\", kernelExecutionTime);\n",
        "  printf(\"Copy from Device Time: %f ms\\n\", copyFromDeviceTime);\n",
        "\n",
        "\n",
        "  //@@ Free the GPU memory here\n",
        "  cudaFree(deviceInput1);\n",
        "  cudaFree(deviceInput2);\n",
        "  cudaFree(deviceOutput);\n",
        "\n",
        "  //@@ Free the CPU memory here\n",
        "  free(hostInput1);\n",
        "  free(hostInput2);\n",
        "  free(hostOutput);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oV14IOZc_JI",
        "outputId": "24ab572e-2ec9-4623-a625-c0310b76bc1b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing lab2_ex1.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc lab2_ex1.cu\n",
        "!ls\n",
        "!./a.out 1024"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZDjDHlcdUJ2",
        "outputId": "3802bbc6-fe99-47ed-8220-96563cf2ba8d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a.out  lab2_ex1.cu  sample_data\n",
            "The input length is 1024\n",
            "Average difference: 0.000000\n",
            "\n",
            "Copy to Device Time: 0.954000 ms\n",
            "Kernel Execution Time: 0.074000 ms\n",
            "Copy from Device Time: 0.030000 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./a.out 1024"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsNQx6ZhmfVC",
        "outputId": "63e8b26e-0218-4825-edee-7a3761551c63"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input length is 1024\n",
            "==707== NVPROF is profiling process 707, command: ./a.out 1024\n",
            "Average difference: 0.000000\n",
            "\n",
            "Copy to Device Time: 0.033000 ms\n",
            "Kernel Execution Time: 0.033000 ms\n",
            "Copy from Device Time: 0.025000 ms\n",
            "==707== Profiling application: ./a.out 1024\n",
            "==707== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   41.14%  4.8310us         1  4.8310us  4.8310us  4.8310us  vecAdd(double*, double*, double*, int)\n",
            "                   37.88%  4.4480us         2  2.2240us  2.0480us  2.4000us  [CUDA memcpy HtoD]\n",
            "                   20.98%  2.4630us         1  2.4630us  2.4630us  2.4630us  [CUDA memcpy DtoH]\n",
            "      API calls:   99.37%  215.08ms         3  71.695ms  2.3820us  215.08ms  cudaMalloc\n",
            "                    0.46%  1.0061ms         1  1.0061ms  1.0061ms  1.0061ms  cuDeviceGetPCIBusId\n",
            "                    0.06%  120.50us       101  1.1930us     140ns  56.891us  cuDeviceGetAttribute\n",
            "                    0.05%  115.65us         3  38.551us  3.4850us  102.71us  cudaFree\n",
            "                    0.03%  54.887us         3  18.295us  11.654us  25.450us  cudaMemcpy\n",
            "                    0.01%  24.788us         1  24.788us  24.788us  24.788us  cuDeviceGetName\n",
            "                    0.01%  22.721us         1  22.721us  22.721us  22.721us  cudaLaunchKernel\n",
            "                    0.01%  13.780us         3  4.5930us     325ns  11.679us  cuDeviceGetCount\n",
            "                    0.00%  7.4330us         1  7.4330us  7.4330us  7.4330us  cudaDeviceSynchronize\n",
            "                    0.00%  1.0540us         2     527ns     298ns     756ns  cuDeviceGet\n",
            "                    0.00%     545ns         1     545ns     545ns     545ns  cuModuleGetLoadingMode\n",
            "                    0.00%     475ns         1     475ns     475ns     475ns  cuDeviceTotalMem\n",
            "                    0.00%     258ns         1     258ns     258ns     258ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ncu --set default --metrics sm__warps_active.avg.pct_of_peak_sustained_active  ./a.out 1024"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtJ3oCQBdoWP",
        "outputId": "754ece50-4722-47f1-d376-a72a9cbce141"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input length is 1024\n",
            "==PROF== Connected to process 731 (/content/a.out)\n",
            "==PROF== Profiling \"vecAdd\" - 0: 0%....50%....100% - 8 passes\n",
            "Average difference: 0.000000\n",
            "\n",
            "Copy to Device Time: 0.069000 ms\n",
            "Kernel Execution Time: 371.724000 ms\n",
            "Copy from Device Time: 0.055000 ms\n",
            "==PROF== Disconnected from process 731\n",
            "[731] a.out@127.0.0.1\n",
            "  vecAdd(double *, double *, double *, int), 2023-Nov-16 23:53:13, Context 1, Stream 7\n",
            "    Section: Command line profiler metrics\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    sm__warps_active.avg.pct_of_peak_sustained_active                                    %                          12.12\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    DRAM Frequency                                                           cycle/nsecond                           4.71\n",
            "    SM Frequency                                                             cycle/usecond                         550.86\n",
            "    Elapsed Cycles                                                                   cycle                          2,186\n",
            "    Memory [%]                                                                           %                           1.59\n",
            "    DRAM Throughput                                                                      %                           1.59\n",
            "    Duration                                                                       usecond                           3.97\n",
            "    L1/TEX Cache Throughput                                                              %                           6.35\n",
            "    L2 Cache Throughput                                                                  %                           1.15\n",
            "    SM Active Cycles                                                                 cycle                         201.72\n",
            "    Compute (SM) [%]                                                                     %                           0.59\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      \n",
            "          waves across all SMs. Look at Launch Statistics for more details.                                             \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Size                                                                                                        128\n",
            "    Function Cache Configuration                                                                  cudaFuncCachePreferNone\n",
            "    Grid Size                                                                                                           8\n",
            "    Registers Per Thread                                                   register/thread                             16\n",
            "    Shared Memory Configuration Size                                                 Kbyte                          32.77\n",
            "    Driver Shared Memory Per Block                                              byte/block                              0\n",
            "    Dynamic Shared Memory Per Block                                             byte/block                              0\n",
            "    Static Shared Memory Per Block                                              byte/block                              0\n",
            "    Threads                                                                         thread                          1,024\n",
            "    Waves Per SM                                                                                                     0.03\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 40              \n",
            "          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      \n",
            "          concurrently with other workloads, consider reducing the block size to have at least one block per            \n",
            "          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    \n",
            "          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            \n",
            "          description for more details on launch configurations.                                                        \n",
            "\n",
            "    Section: Occupancy\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Limit SM                                                                   block                             16\n",
            "    Block Limit Registers                                                            block                             32\n",
            "    Block Limit Shared Mem                                                           block                             16\n",
            "    Block Limit Warps                                                                block                              8\n",
            "    Theoretical Active Warps per SM                                                   warp                             32\n",
            "    Theoretical Occupancy                                                                %                            100\n",
            "    Achieved Occupancy                                                                   %                          12.12\n",
            "    Achieved Active Warps Per SM                                                      warp                           3.88\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
            "          theoretical (100.0%) and measured achieved occupancy (12.1%) can be the result of warp scheduling overheads   \n",
            "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
            "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
            "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ncu --set default --metrics sm__warps_active.avg.pct_of_peak_sustained_active  ./a.out 131070"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMiGcCzFfXon",
        "outputId": "d42979cb-64ac-4232-c683-7b762ea115c0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input length is 131070\n",
            "==PROF== Connected to process 754 (/content/a.out)\n",
            "==PROF== Profiling \"vecAdd\" - 0: 0%....50%....100% - 8 passes\n",
            "Average difference: 0.000000\n",
            "\n",
            "Copy to Device Time: 0.662000 ms\n",
            "Kernel Execution Time: 517.237000 ms\n",
            "Copy from Device Time: 0.985000 ms\n",
            "==PROF== Disconnected from process 754\n",
            "[754] a.out@127.0.0.1\n",
            "  vecAdd(double *, double *, double *, int), 2023-Nov-16 23:53:15, Context 1, Stream 7\n",
            "    Section: Command line profiler metrics\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    sm__warps_active.avg.pct_of_peak_sustained_active                                    %                          77.43\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    DRAM Frequency                                                           cycle/nsecond                           4.51\n",
            "    SM Frequency                                                             cycle/usecond                         528.54\n",
            "    Elapsed Cycles                                                                   cycle                          6,481\n",
            "    Memory [%]                                                                           %                          64.03\n",
            "    DRAM Throughput                                                                      %                          64.03\n",
            "    Duration                                                                       usecond                          12.26\n",
            "    L1/TEX Cache Throughput                                                              %                          32.06\n",
            "    L2 Cache Throughput                                                                  %                          32.73\n",
            "    SM Active Cycles                                                                 cycle                       5,110.10\n",
            "    Compute (SM) [%]                                                                     %                          25.29\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Size                                                                                                        128\n",
            "    Function Cache Configuration                                                                  cudaFuncCachePreferNone\n",
            "    Grid Size                                                                                                       1,024\n",
            "    Registers Per Thread                                                   register/thread                             16\n",
            "    Shared Memory Configuration Size                                                 Kbyte                          32.77\n",
            "    Driver Shared Memory Per Block                                              byte/block                              0\n",
            "    Dynamic Shared Memory Per Block                                             byte/block                              0\n",
            "    Static Shared Memory Per Block                                              byte/block                              0\n",
            "    Threads                                                                         thread                        131,072\n",
            "    Waves Per SM                                                                                                     3.20\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    \n",
            "          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       \n",
            "          occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 64 thread blocks.   \n",
            "          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   \n",
            "          up to 25.0% of the total kernel runtime with a lower occupancy of 22.6%. Try launching a grid with no         \n",
            "          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  \n",
            "          a grid. See the Hardware Model                                                                                \n",
            "          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      \n",
            "          details on launch configurations.                                                                             \n",
            "\n",
            "    Section: Occupancy\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Limit SM                                                                   block                             16\n",
            "    Block Limit Registers                                                            block                             32\n",
            "    Block Limit Shared Mem                                                           block                             16\n",
            "    Block Limit Warps                                                                block                              8\n",
            "    Theoretical Active Warps per SM                                                   warp                             32\n",
            "    Theoretical Occupancy                                                                %                            100\n",
            "    Achieved Occupancy                                                                   %                          77.43\n",
            "    Achieved Active Warps Per SM                                                      warp                          24.78\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n",
            "          theoretical (100.0%) and measured achieved occupancy (77.4%) can be the result of warp scheduling overheads   \n",
            "          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n",
            "          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n",
            "          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out 1024"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6BiQW5Hm_3Q",
        "outputId": "6b381fd1-1996-4106-cd6a-4ad76660df0e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input length is 1024\n",
            "Average difference: 0.000000\n",
            "\n",
            "Copy to Device Time: 0.042000 ms\n",
            "Kernel Execution Time: 0.028000 ms\n",
            "Copy from Device Time: 0.023000 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out 8092"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TAMsSbCTvoR",
        "outputId": "369bea6c-d256-43f8-a413-4feef751017d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input length is 8092\n",
            "Average difference: 0.000000\n",
            "\n",
            "Copy to Device Time: 0.088000 ms\n",
            "Kernel Execution Time: 0.029000 ms\n",
            "Copy from Device Time: 0.070000 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out 65000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7jzOXd3Tvdp",
        "outputId": "24cc6765-9460-44c4-b612-b15e3db5344c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input length is 65000\n",
            "Average difference: 0.000000\n",
            "\n",
            "Copy to Device Time: 0.306000 ms\n",
            "Kernel Execution Time: 0.061000 ms\n",
            "Copy from Device Time: 0.421000 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out 250000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DG4CiStTvSx",
        "outputId": "4b7eea24-3c54-49c9-a70a-4fa4c853893c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input length is 250000\n",
            "Average difference: 0.000000\n",
            "\n",
            "Copy to Device Time: 1.047000 ms\n",
            "Kernel Execution Time: 0.109000 ms\n",
            "Copy from Device Time: 1.484000 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out 2000000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdM0UjZCTvFp",
        "outputId": "3972b75a-1f30-4ae4-e357-54dac7aa7702"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input length is 2000000\n",
            "Average difference: 0.000000\n",
            "\n",
            "Copy to Device Time: 6.998000 ms\n",
            "Kernel Execution Time: 0.230000 ms\n",
            "Copy from Device Time: 12.088000 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out 120000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuB6D9RLTu4a",
        "outputId": "a6ff80a0-5209-4c48-813f-3241ccf1279e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input length is 120000\n",
            "Average difference: 0.000000\n",
            "\n",
            "Copy to Device Time: 0.570000 ms\n",
            "Kernel Execution Time: 0.099000 ms\n",
            "Copy from Device Time: 0.762000 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out 12000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofJU4DckTupB",
        "outputId": "fdf4ef51-a4f4-4372-9761-1b08fc31d2e6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input length is 12000\n",
            "Average difference: 0.000000\n",
            "\n",
            "Copy to Device Time: 0.089000 ms\n",
            "Kernel Execution Time: 0.027000 ms\n",
            "Copy from Device Time: 0.082000 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out 4000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bk84-wRTuVg",
        "outputId": "9a27fe7d-18c3-4e4d-91b5-e526571ccc26"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input length is 4000\n",
            "Average difference: 0.000000\n",
            "\n",
            "Copy to Device Time: 0.051000 ms\n",
            "Kernel Execution Time: 0.025000 ms\n",
            "Copy from Device Time: 0.047000 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Rf4usHqjPNN",
        "outputId": "1e4cb1e2-4464-4ce6-8e96-6566d8e5f916"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input length is 1\n",
            "Average difference: 0.000000\n",
            "\n",
            "Copy to Device Time: 0.032000 ms\n",
            "Kernel Execution Time: 0.025000 ms\n",
            "Copy from Device Time: 0.016000 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out 128"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U705UIxjOrV",
        "outputId": "be5addaa-184e-45ae-c12e-1c788e130612"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input length is 128\n",
            "Average difference: 0.000000\n",
            "\n",
            "Copy to Device Time: 0.034000 ms\n",
            "Kernel Execution Time: 0.025000 ms\n",
            "Copy from Device Time: 0.018000 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out 131070"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-I6uGlJgjOW1",
        "outputId": "027d56b9-2e54-4cd0-ce33-41aedc1bd9fc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input length is 131070\n",
            "Average difference: 0.000000\n",
            "\n",
            "Copy to Device Time: 0.728000 ms\n",
            "Kernel Execution Time: 0.105000 ms\n",
            "Copy from Device Time: 0.864000 ms\n"
          ]
        }
      ]
    }
  ]
}